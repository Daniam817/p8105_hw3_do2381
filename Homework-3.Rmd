---
title: "Homework 3"
author: "Daniel Ojeranti"
date: "10/7/2020"
output: github_document
---

```{r, setup, echo = F, message = FALSE, warning=FALSE}
library(tidyverse)
library(p8105.datasets)
library(hexbin)
library(ggridges)
library(patchwork)
knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```


### Problem 1

```{r,echo = F, message = FALSE, warning=FALSE}
data("instacart")
```

The "instacart" dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

```{r,echo = F, message = FALSE, warning=FALSE}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))

aisle.df =
  instacart %>% 
	count(aisle) 
```

There are a total of`r nrow(aisle.df) ` aisles, and the most ordered items are fresh vegetables.


**A scatterplot showing the number of items ordered in each aisle.**

```{r, echo = F, message = FALSE, warning=FALSE}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


**This table shows us the three most popular items in each aisle.**

```{r, echo = F, message = FALSE, warning = FALSE}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


**In this table, we see the mean hour of day where "Pink Lady Apples" and "coffee Ice Cream" are ordered each day of the week.**

```{r, echo = F, message = FALSE, warning = FALSE}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	) %>% 
  knitr::kable()
```


## Problem 2

```{r, echo = F, message = FALSE, warning = FALSE}
accel.df =
  read_csv("~/Columbia Semester 1 Files/Data Science  R Code/Visualization and EDA/Visualization_EDA/accel_data.csv") %>% 
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity",
    values_to = "activity_count"
) %>% 
  mutate(
    weekday_weekend = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday"),
    minute = as.numeric(sub("_", "", minute)))
                  
```

The "accel" dataset contains `r nrow(accel.df)` rows and `r ncol(accel.df)` columns. 

Observations are  five weeks of accelerometer data collected on a 63 year-old male. The observations include the week, day, day_id representing the day as a numeric value, minute of the day, activity count, and weekend vs. weekday variable.

```{r, echo = F, message = FALSE, warning=FALSE }
Total.activity =
  accel.df %>%
  mutate(day = fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>% 
	group_by(day, week) %>%
  summarize(total_activity = sum(activity_count)) %>% 
  arrange(week,day) %>%
  ggplot(aes(x = day, y = total_activity)) +
  geom_point(aes(color = day), alpha = .5) +
  geom_line(alpha = .2) +
  facet_grid(.~week) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(title = "Total activity per day  across weeks",
     x = "Year", 
     y = "Total Activity")
```

```{r, echo = F, message = FALSE, warning=FALSE }
  
accel.df %>%
  mutate(day = fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>% 
	group_by(day, week) %>%
  summarize(total_activity = sum(activity_count)) %>% 
  arrange(week,day) %>%
  knitr::kable()

```

In weeks 1, 2, and 5 there seems to be a general increase in activity throughout the week. On week 3, the total activity seems constant throughout the days and on week 4 it seemed to decrease throughout the week. In the last 2 weeks, the patient recorded its lowest times in activity for Saturday and Sunday. 



**Accelerometer data of 24 hour activity per day**

```{r, echo = F, message = FALSE, warning=FALSE}

accel.df %>%
  ggplot(aes(x = minute, y = activity_count)) +
  geom_point(aes(color = day), alpha = .5) +
  geom_line(alpha = .2) +
  geom_smooth()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
   scale_x_continuous(
       breaks = c(0,60,120,180,240,300,360,420,480,540,600,660,720,780,840,900,960,1020,1080,1140,1200,1260,1320,1380,1440)
        ) +
    scale_y_continuous(
       breaks = c(0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000)
    )

```

There seems to be a general increase in activity starting from minute 360 (6am) and it changes throughout the day.
The patients activity seems to be constant throughout the day and tends to decrease from 1260th minute of the day (9pm).


## Problem 3

```{r, include = F, message = FALSE, warning=FALSE }
data("ny_noaa")

sum(is.na(ny_noaa))
  
```

The NOAA dataset contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns and there are `r sum(is.na(ny_noaa))` missing values. 

This dataset comes from the NOAA which provides public access to weather data. Observations include the weather station ID, date, precipitation in millimeters, snowfall in millimeters, snow depth in millimeters, maximum temperatures and minimum temperatures, both in Celsius.
  
  
```{r, echo = F, message = FALSE, warning=FALSE}
  ny.df = 
  ny_noaa %>% 
  janitor::clean_names() %>%
  separate(date, c("year","month","day"), sep = "-") %>% 
  mutate(tmax = as.numeric(tmax)/10,
         tmin = as.numeric(tmin)/10,
         prcp = prcp/10)
```

```{r, echo = F, message = FALSE, warning=FALSE}
  ny.df %>% 
  count(snow) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank == 1)
```

The most commonly observed value of snowfall is 0. This is probably because there are more days where there isn't snow compared to the amount of day where there is snow. Also, snow levels are partitioned by millimeters so it makes sense that there are more days with no snowfall then days with any depth of snow.

```{r, echo = F, message = FALSE, warning=FALSE}
ny.df %>%
filter( month %in% c("01", "07")) %>%
group_by(id, year, month) %>%
summarize(avg_tmax = mean(tmax, na.rm = TRUE)) %>%
ggplot(aes(x = year, y = avg_tmax, group = id)) +
geom_point() +
geom_path() +
facet_grid(~ month) +
labs(title = "Average Mean Max Tempratures for January and July in each station across Years",
     x = "Year", 
     y = "Average Max Temperature (C)") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+
theme(plot.margin=unit(c(1,2,1,1),"cm"))

```

In this plot it seems that the the average max temperatures in July are higher generally when compared to January.
This makes sense because July is in the summer and January is in the winter. We expect there to be higher temperatures during the summer. THere are a couple of outliers as well. In the January of year 1982, there was a max average temp of below -10 degrees celsius. Also in the July of year 1998 there was a max average temp of about 15 degrees celsius which isn't typical.


**Hexplot of Maximum Temperature by Minimum Temperature and Plot of Snowfall by Year.**

```{r, include = F, message = FALSE, warning=FALSE}
min.max.df =
  ny.df %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex() +
  theme(legend.position = "right") +
  labs(title = "Maximum Temprature by Minimum Temperature", 
       x = "Minimum Temprature", 
       y = "Maximum Temperature")+
  theme(plot.margin=unit(c(1,2,1,1),"cm"))

snow.df =
  ny.df %>% 
  filter(  snow > 0, snow < 100 ) %>% 
  ggplot(aes(x = year , y = snow, fill = year)) + 
  geom_violin() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = .5)) +
   labs(title = "Snowfall by Year (Range from 0-100 (mm))", 
       x = "Year", 
       y = "Snowfall")+
  theme(plot.margin=unit(c(1,2,1,1),"cm"))
        

```

```{r, echo = F, message = FALSE, warning=FALSE}

final.df = snow.df + min.max.df

```

In the first plot we observe a hexplot of maximum temperature by minimum temperature. The more frequent observartion are towards the inner diagonal of the data where counts reach upwards to 5000.
In the second plot we observe a violin distribution of snowfall ranging from 0 to 100 millimeters by year. As we can see throughout the years, the distribution seems to be relatively consistent.

